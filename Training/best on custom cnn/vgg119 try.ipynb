{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1561c007-7efb-4b78-9bf6-42e112682170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8725 images belonging to 105 classes.\n",
      "Found 1837 images belonging to 105 classes.\n",
      "Found 1972 images belonging to 105 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 7, 7, 512)         20024384  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              51382272  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 105)               215145    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71,621,801\n",
      "Trainable params: 56,317,033\n",
      "Non-trainable params: 15,304,768\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "272/272 [==============================] - ETA: 0s - loss: 3.2387 - accuracy: 0.2611\n",
      "Epoch 1: val_loss improved from inf to 0.82248, saving model to H:\\1.organized\\allModel\\2.vgg19_modeltry.h5\n",
      "272/272 [==============================] - 199s 701ms/step - loss: 3.2387 - accuracy: 0.2611 - val_loss: 0.8225 - val_accuracy: 0.7884\n",
      "Epoch 2/5\n",
      "272/272 [==============================] - ETA: 0s - loss: 1.0034 - accuracy: 0.7186\n",
      "Epoch 2: val_loss improved from 0.82248 to 0.18602, saving model to H:\\1.organized\\allModel\\2.vgg19_modeltry.h5\n",
      "272/272 [==============================] - 125s 456ms/step - loss: 1.0034 - accuracy: 0.7186 - val_loss: 0.1860 - val_accuracy: 0.9472\n",
      "Epoch 3/5\n",
      "272/272 [==============================] - ETA: 0s - loss: 0.4771 - accuracy: 0.8595\n",
      "Epoch 3: val_loss improved from 0.18602 to 0.07927, saving model to H:\\1.organized\\allModel\\2.vgg19_modeltry.h5\n",
      "272/272 [==============================] - 184s 673ms/step - loss: 0.4771 - accuracy: 0.8595 - val_loss: 0.0793 - val_accuracy: 0.9728\n",
      "Epoch 4/5\n",
      "272/272 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.9194\n",
      "Epoch 4: val_loss improved from 0.07927 to 0.03671, saving model to H:\\1.organized\\allModel\\2.vgg19_modeltry.h5\n",
      "272/272 [==============================] - 137s 501ms/step - loss: 0.2690 - accuracy: 0.9194 - val_loss: 0.0367 - val_accuracy: 0.9857\n",
      "Epoch 5/5\n",
      "272/272 [==============================] - ETA: 0s - loss: 0.2031 - accuracy: 0.9391\n",
      "Epoch 5: val_loss did not improve from 0.03671\n",
      "272/272 [==============================] - 64s 234ms/step - loss: 0.2031 - accuracy: 0.9391 - val_loss: 0.0369 - val_accuracy: 0.9872\n",
      "58/58 [==============================] - 11s 198ms/step - loss: 0.0286 - accuracy: 0.9907\n",
      "Test Accuracy: 0.9907457828521729\n",
      "58/58 [==============================] - 5s 80ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cow_1       1.00      1.00      1.00        14\n",
      "      cow_10       1.00      1.00      1.00        25\n",
      "     cow_101       1.00      0.80      0.89        10\n",
      "     cow_110       1.00      1.00      1.00         8\n",
      "     cow_112       1.00      1.00      1.00        21\n",
      "     cow_113       1.00      1.00      1.00        21\n",
      "     cow_124       1.00      1.00      1.00        18\n",
      "     cow_126       1.00      1.00      1.00        18\n",
      "     cow_127       1.00      1.00      1.00        27\n",
      "     cow_129       1.00      1.00      1.00        11\n",
      "      cow_13       1.00      1.00      1.00        25\n",
      "     cow_140       1.00      1.00      1.00        12\n",
      "     cow_157       1.00      1.00      1.00        14\n",
      "     cow_158       1.00      1.00      1.00        10\n",
      "     cow_168       0.95      1.00      0.97        18\n",
      "      cow_17       1.00      1.00      1.00        20\n",
      "     cow_179       1.00      1.00      1.00        10\n",
      "     cow_190       1.00      1.00      1.00        28\n",
      "     cow_196       1.00      1.00      1.00        10\n",
      "       cow_2       1.00      1.00      1.00        14\n",
      "     cow_201       1.00      1.00      1.00        36\n",
      "     cow_210       1.00      1.00      1.00        13\n",
      "     cow_212       1.00      1.00      1.00        21\n",
      "     cow_217       1.00      0.86      0.92         7\n",
      "     cow_223       1.00      1.00      1.00        10\n",
      "     cow_224       1.00      1.00      1.00        25\n",
      "     cow_235       1.00      1.00      1.00        43\n",
      "      cow_24       1.00      1.00      1.00        10\n",
      "     cow_246       1.00      1.00      1.00        18\n",
      "     cow_247       1.00      1.00      1.00        10\n",
      "     cow_248       1.00      1.00      1.00         9\n",
      "     cow_249       1.00      1.00      1.00        14\n",
      "     cow_252       1.00      1.00      1.00        14\n",
      "     cow_255       1.00      1.00      1.00        21\n",
      "     cow_257       1.00      1.00      1.00        21\n",
      "     cow_258       0.97      1.00      0.99        36\n",
      "     cow_259       1.00      1.00      1.00        21\n",
      "     cow_261       1.00      1.00      1.00         5\n",
      "     cow_262       1.00      1.00      1.00        28\n",
      "     cow_263       1.00      1.00      1.00        23\n",
      "     cow_264       1.00      1.00      1.00        14\n",
      "     cow_265       0.83      1.00      0.91        10\n",
      "     cow_266       1.00      1.00      1.00         7\n",
      "     cow_267       1.00      1.00      1.00        21\n",
      "     cow_268       1.00      1.00      1.00        28\n",
      "     cow_269       1.00      0.86      0.92        14\n",
      "      cow_27       1.00      1.00      1.00        26\n",
      "     cow_270       1.00      1.00      1.00        25\n",
      "     cow_271       1.00      0.60      0.75         5\n",
      "     cow_273       0.83      1.00      0.91        10\n",
      "     cow_274       1.00      1.00      1.00         7\n",
      "     cow_275       1.00      1.00      1.00         7\n",
      "     cow_279       1.00      1.00      1.00        28\n",
      "     cow_280       1.00      1.00      1.00        14\n",
      "     cow_283       1.00      1.00      1.00        18\n",
      "     cow_285       1.00      1.00      1.00        43\n",
      "     cow_286       1.00      1.00      1.00         5\n",
      "     cow_287       1.00      1.00      1.00        10\n",
      "     cow_288       1.00      1.00      1.00        43\n",
      "     cow_289       1.00      1.00      1.00        25\n",
      "     cow_292       1.00      1.00      1.00        32\n",
      "     cow_293       1.00      1.00      1.00        14\n",
      "     cow_295       1.00      1.00      1.00        18\n",
      "     cow_296       1.00      1.00      1.00        21\n",
      "     cow_298       1.00      1.00      1.00        18\n",
      "     cow_299       1.00      1.00      1.00        10\n",
      "     cow_300       1.00      1.00      1.00        10\n",
      "     cow_301       1.00      1.00      1.00        36\n",
      "     cow_302       1.00      1.00      1.00        21\n",
      "     cow_304       1.00      1.00      1.00         5\n",
      "     cow_309       1.00      1.00      1.00        14\n",
      "     cow_311       1.00      1.00      1.00        16\n",
      "     cow_312       1.00      1.00      1.00        10\n",
      "     cow_314       1.00      1.00      1.00         8\n",
      "     cow_315       1.00      1.00      1.00         8\n",
      "      cow_32       1.00      1.00      1.00        25\n",
      "     cow_320       1.00      1.00      1.00        18\n",
      "     cow_327       1.00      1.00      1.00        12\n",
      "     cow_328       1.00      1.00      1.00        20\n",
      "     cow_331       1.00      0.94      0.97        18\n",
      "     cow_333       1.00      1.00      1.00        15\n",
      "     cow_334       0.75      0.46      0.57        13\n",
      "     cow_336       1.00      1.00      1.00        21\n",
      "     cow_337       1.00      1.00      1.00        13\n",
      "      cow_34       1.00      1.00      1.00        30\n",
      "     cow_342       1.00      1.00      1.00        21\n",
      "     cow_343       0.56      0.82      0.67        11\n",
      "     cow_349       1.00      1.00      1.00        14\n",
      "      cow_35       0.95      1.00      0.97        18\n",
      "     cow_352       1.00      1.00      1.00        13\n",
      "      cow_40       1.00      1.00      1.00        17\n",
      "       cow_5       1.00      1.00      1.00        14\n",
      "      cow_55       1.00      1.00      1.00        16\n",
      "      cow_58       1.00      1.00      1.00        23\n",
      "      cow_64       1.00      1.00      1.00        12\n",
      "      cow_68       0.97      1.00      0.99        36\n",
      "      cow_69       1.00      1.00      1.00        21\n",
      "      cow_74       1.00      1.00      1.00        20\n",
      "      cow_79       1.00      1.00      1.00        14\n",
      "       cow_8       1.00      1.00      1.00        17\n",
      "      cow_80       1.00      1.00      1.00        26\n",
      "      cow_83       1.00      1.00      1.00         7\n",
      "      cow_84       1.00      1.00      1.00        12\n",
      "      cow_88       1.00      1.00      1.00         8\n",
      "      cow_90       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           0.99      1837\n",
      "   macro avg       0.99      0.98      0.99      1837\n",
      "weighted avg       0.99      0.99      0.99      1837\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14  0  0 ...  0  0  0]\n",
      " [ 0 25  0 ...  0  0  0]\n",
      " [ 0  0  8 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 12  0  0]\n",
      " [ 0  0  0 ...  0  8  0]\n",
      " [ 0  0  0 ...  0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Paths to your data directories\n",
    "train_path = r\"H:\\2.vgg19 image procced\\preprocced_data_with_split\\train\"\n",
    "test_path = r\"H:\\2.vgg19 image procced\\preprocced_data_with_split\\test\"\n",
    "val_path = r\"H:\\2.vgg19 image procced\\preprocced_data_with_split\\val\"\n",
    "IMG_SIZE = (224, 224)  # Adjusted for VGG19 input size\n",
    "\n",
    "# Directory to save models and history\n",
    "save_dir = r\"H:\\1.organized\\allModel\"\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 32\n",
    "num_classes = 105\n",
    "epochs = 5\n",
    "\n",
    "# Create data generators for image preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Data generators for training, testing, and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Keep the order for evaluation\n",
    ")\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    val_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load the pre-trained VGG19 model\n",
    "base_model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers except the last few layers\n",
    "for layer in base_model_vgg19.layers[:-3]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a custom top classifier for the number of classes using VGG19\n",
    "model_vgg19 = Sequential()\n",
    "model_vgg19.add(base_model_vgg19)\n",
    "model_vgg19.add(Flatten())\n",
    "model_vgg19.add(Dense(2048, activation='relu'))\n",
    "model_vgg19.add(Dropout(0.5))  # Adjust dropout as needed\n",
    "model_vgg19.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_vgg19.summary()\n",
    "\n",
    "# Compile VGG19 model\n",
    "model_vgg19.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define the checkpoint callback to save the model\n",
    "checkpoint_path = os.path.join(save_dir, '2.vgg19_modeltry.h5')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model and save the history\n",
    "history_vgg19 = model_vgg19.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# Save model architecture to JSON (for future use in prediction)\n",
    "model_json = model_vgg19.to_json()\n",
    "with open(os.path.join(save_dir, '2.model_vgg19try.json'), 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save label mapping as JSON (assuming you have train_generator.class_indices)\n",
    "label_map = train_generator.class_indices\n",
    "with open(os.path.join(save_dir, '2.vgg19label_maptry.json'), 'w') as json_file:\n",
    "    json.dump(label_map, json_file)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model_vgg19.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model_vgg19.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels from the generator\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Generate a classification report and confusion matrix\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c2f985e-824e-4da8-9a0c-a4f63d1cba5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Load your VGG19 model and label mapping\n",
    "save_dir = r\"H:\\1.organized\\allModel\"\n",
    "model_path = os.path.join(save_dir, '2.vgg19_modeltry.h5')\n",
    "label_map_path = os.path.join(save_dir, '2.vgg19label_maptry.json')\n",
    "\n",
    "# Load model and class labels\n",
    "model = load_model(model_path)\n",
    "with open(label_map_path, 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "    class_labels = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Function to preprocess image for prediction\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "# Function to handle image prediction\n",
    "def predict_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        try:\n",
    "            # Preprocess the image\n",
    "            img_array = preprocess_image(file_path)\n",
    "\n",
    "            # Make prediction\n",
    "            prediction = model.predict(img_array)\n",
    "            predicted_class = np.argmax(prediction)\n",
    "            class_name = class_labels[predicted_class]\n",
    "\n",
    "            # Display prediction\n",
    "            result_label.config(text=f\"Prediction: {class_name}\")\n",
    "            \n",
    "            # Display the image\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((300, 300), Image.ANTIALIAS)\n",
    "            img = ImageTk.PhotoImage(img)\n",
    "            panel.configure(image=img)\n",
    "            panel.image = img  # keep a reference\n",
    "            \n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error predicting image: {e}\")\n",
    "\n",
    "# Create main application window\n",
    "root = tk.Tk()\n",
    "root.title(\"Image Classifier\")\n",
    "\n",
    "# Create GUI components\n",
    "btn_load = tk.Button(root, text=\"Load Image\", command=predict_image)\n",
    "btn_load.pack(pady=20)\n",
    "\n",
    "result_label = tk.Label(root, text=\"Prediction: \")\n",
    "result_label.pack()\n",
    "\n",
    "panel = tk.Label(root)  # for displaying the loaded image\n",
    "panel.pack(padx=10, pady=10)\n",
    "\n",
    "# Run the main event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17fbc8-b47f-47cc-b32e-cef90bfd2f86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
