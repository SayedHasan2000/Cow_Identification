{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9672560-d5a5-4139-9c86-1a77c6fd1d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in c:\\users\\sayed\\anaconda3\\envs\\tf\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in c:\\users\\sayed\\anaconda3\\envs\\tf\\lib\\site-packages (from keras-tuner) (2.10.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\sayed\\anaconda3\\envs\\tf\\lib\\site-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: requests in c:\\users\\sayed\\anaconda3\\envs\\tf\\lib\\site-packages (from keras-tuner) (2.31.0)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\sayed\\anaconda3\\envs\\tf\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sayed\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sayed\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->keras-tuner) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sayed\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->keras-tuner) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sayed\\anaconda3\\envs\\tf\\lib\\site-packages (from requests->keras-tuner) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8796993c-8c9b-4093-90e6-0fceafea9688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayed\\AppData\\Local\\Temp\\ipykernel_752\\3944463045.py:11: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import kerastuner as kt\n",
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "# Directories where your input images are located (train, test, and validation)\n",
    "train_dir = r\"F:\\Thesis\\0.WorkHere\\Train\"\n",
    "test_dir = r\"F:\\Thesis\\0.WorkHere\\Test\"\n",
    "validation_dir = r\"F:\\Thesis\\0.WorkHere\\Validation\"\n",
    "\n",
    "# Directory to save models and history\n",
    "save_dir = r\"F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\"\n",
    "\n",
    "# Set hyperparameters\n",
    "batch_size = 5\n",
    "num_classes = 169\n",
    "epochs = 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf48677-7f05-45a1-8e8b-aa355f981b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5509 images belonging to 169 classes.\n",
      "Found 568 images belonging to 169 classes.\n",
      "Found 986 images belonging to 169 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create data generators for image preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Create data generators for training, testing, and validation data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab580b0e-c81e-40f9-9aeb-1a3947f7a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to build the model with hyperparameters\n",
    "def build_model(hp):\n",
    "    base_model_vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model_vgg19.trainable = False  # Freeze the base model\n",
    "\n",
    "    # Define hyperparameters\n",
    "    hp_units = hp.Int('units', min_value=512, max_value=2048, step=512)\n",
    "    hp_dropout = hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model_vgg19,\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(units=hp_units, activation='relu'),\n",
    "        layers.Dropout(rate=hp_dropout),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp_learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349edd2-e4e5-4211-8998-0e18ee3227ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d804f7a2-7fb8-47f3-b306-acb03b264579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 60 Complete [00h 08m 20s]\n",
      "val_accuracy: 0.01217038556933403\n",
      "\n",
      "Best val_accuracy So Far: 0.7809330821037292\n",
      "Total elapsed time: 03h 25m 09s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 2048 and the optimal dropout rate is 0.0.\n",
      "The optimal learning rate for the optimizer is 0.0001.\n",
      "\n",
      "Epoch 1/20\n",
      "1105/1106 [============================>.] - ETA: 0s - loss: 4.8463 - accuracy: 0.0481\n",
      "Epoch 1: val_loss improved from inf to 4.25244, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 52s 46ms/step - loss: 4.8462 - accuracy: 0.0481 - val_loss: 4.2524 - val_accuracy: 0.1197\n",
      "Epoch 2/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 3.8541 - accuracy: 0.1722\n",
      "Epoch 2: val_loss improved from 4.25244 to 3.25136, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 3.8541 - accuracy: 0.1722 - val_loss: 3.2514 - val_accuracy: 0.2921\n",
      "Epoch 3/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 3.0618 - accuracy: 0.3208\n",
      "Epoch 3: val_loss improved from 3.25136 to 2.54749, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 52s 47ms/step - loss: 3.0618 - accuracy: 0.3208 - val_loss: 2.5475 - val_accuracy: 0.4493\n",
      "Epoch 4/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 2.4721 - accuracy: 0.4582\n",
      "Epoch 4: val_loss improved from 2.54749 to 1.97685, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 47ms/step - loss: 2.4721 - accuracy: 0.4582 - val_loss: 1.9768 - val_accuracy: 0.5365\n",
      "Epoch 5/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 2.0186 - accuracy: 0.5447\n",
      "Epoch 5: val_loss improved from 1.97685 to 1.69034, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 2.0186 - accuracy: 0.5447 - val_loss: 1.6903 - val_accuracy: 0.5862\n",
      "Epoch 6/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 1.6797 - accuracy: 0.6266\n",
      "Epoch 6: val_loss improved from 1.69034 to 1.38072, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 1.6797 - accuracy: 0.6266 - val_loss: 1.3807 - val_accuracy: 0.6450\n",
      "Epoch 7/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 1.4504 - accuracy: 0.6658\n",
      "Epoch 7: val_loss improved from 1.38072 to 1.18657, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 1.4504 - accuracy: 0.6658 - val_loss: 1.1866 - val_accuracy: 0.6998\n",
      "Epoch 8/20\n",
      "1105/1106 [============================>.] - ETA: 0s - loss: 1.2227 - accuracy: 0.7187\n",
      "Epoch 8: val_loss improved from 1.18657 to 1.00586, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 1.2223 - accuracy: 0.7190 - val_loss: 1.0059 - val_accuracy: 0.7434\n",
      "Epoch 9/20\n",
      "1105/1106 [============================>.] - ETA: 0s - loss: 1.0721 - accuracy: 0.7486\n",
      "Epoch 9: val_loss improved from 1.00586 to 0.84857, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 1.0716 - accuracy: 0.7486 - val_loss: 0.8486 - val_accuracy: 0.7779\n",
      "Epoch 10/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 0.9526 - accuracy: 0.7776\n",
      "Epoch 10: val_loss improved from 0.84857 to 0.76462, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 0.9526 - accuracy: 0.7776 - val_loss: 0.7646 - val_accuracy: 0.7972\n",
      "Epoch 11/20\n",
      "1105/1106 [============================>.] - ETA: 0s - loss: 0.8539 - accuracy: 0.7902\n",
      "Epoch 11: val_loss improved from 0.76462 to 0.75219, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 0.8536 - accuracy: 0.7904 - val_loss: 0.7522 - val_accuracy: 0.7931\n",
      "Epoch 12/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 0.7654 - accuracy: 0.8092\n",
      "Epoch 12: val_loss improved from 0.75219 to 0.68900, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 54s 49ms/step - loss: 0.7654 - accuracy: 0.8092 - val_loss: 0.6890 - val_accuracy: 0.8195\n",
      "Epoch 13/20\n",
      "1105/1106 [============================>.] - ETA: 0s - loss: 0.6885 - accuracy: 0.8299\n",
      "Epoch 13: val_loss improved from 0.68900 to 0.60554, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 0.6884 - accuracy: 0.8298 - val_loss: 0.6055 - val_accuracy: 0.8428\n",
      "Epoch 14/20\n",
      "1105/1106 [============================>.] - ETA: 0s - loss: 0.6508 - accuracy: 0.8306\n",
      "Epoch 14: val_loss improved from 0.60554 to 0.54136, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 0.6507 - accuracy: 0.8306 - val_loss: 0.5414 - val_accuracy: 0.8519\n",
      "Epoch 15/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 0.5849 - accuracy: 0.8514\n",
      "Epoch 15: val_loss improved from 0.54136 to 0.53833, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 54s 48ms/step - loss: 0.5849 - accuracy: 0.8514 - val_loss: 0.5383 - val_accuracy: 0.8479\n",
      "Epoch 16/20\n",
      "1105/1106 [============================>.] - ETA: 0s - loss: 0.5557 - accuracy: 0.8559\n",
      "Epoch 16: val_loss improved from 0.53833 to 0.49320, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 53s 48ms/step - loss: 0.5556 - accuracy: 0.8561 - val_loss: 0.4932 - val_accuracy: 0.8529\n",
      "Epoch 17/20\n",
      "1105/1106 [============================>.] - ETA: 0s - loss: 0.5120 - accuracy: 0.8641\n",
      "Epoch 17: val_loss did not improve from 0.49320\n",
      "1106/1106 [==============================] - 49s 44ms/step - loss: 0.5117 - accuracy: 0.8642 - val_loss: 0.5271 - val_accuracy: 0.8550\n",
      "Epoch 18/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 0.4769 - accuracy: 0.8769\n",
      "Epoch 18: val_loss improved from 0.49320 to 0.46189, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 54s 48ms/step - loss: 0.4769 - accuracy: 0.8769 - val_loss: 0.4619 - val_accuracy: 0.8702\n",
      "Epoch 19/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 0.4549 - accuracy: 0.8796\n",
      "Epoch 19: val_loss improved from 0.46189 to 0.45511, saving model to F:\\Thesis\\0.WorkHere\\SavedModels\\Tuned Models\\vgg19_model_tuned.h5\n",
      "1106/1106 [==============================] - 54s 48ms/step - loss: 0.4549 - accuracy: 0.8796 - val_loss: 0.4551 - val_accuracy: 0.8732\n",
      "Epoch 20/20\n",
      "1106/1106 [==============================] - ETA: 0s - loss: 0.4173 - accuracy: 0.8854\n",
      "Epoch 20: val_loss did not improve from 0.45511\n",
      "1106/1106 [==============================] - 49s 44ms/step - loss: 0.4173 - accuracy: 0.8854 - val_loss: 0.4753 - val_accuracy: 0.8611\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    hyperband_iterations=2,\n",
    "    directory='hyperband',\n",
    "    project_name='keras_tuner_demo'\n",
    ")\n",
    "\n",
    "# Perform hyperparameter search\n",
    "tuner.search(train_generator,\n",
    "             validation_data=validation_generator,\n",
    "             epochs=10,\n",
    "             callbacks=[ModelCheckpoint(\n",
    "                 filepath=save_dir + '/vgg19_model_{epoch}.h5',\n",
    "                 monitor='val_loss',\n",
    "                 save_best_only=True,\n",
    "                 verbose=1\n",
    "             )])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal dropout rate is {best_hps.get('dropout')}.\n",
    "The optimal learning rate for the optimizer is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n",
    "\n",
    "# Build the model with the optimal hyperparameters and train it on the data\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[ModelCheckpoint(\n",
    "        filepath=save_dir + '/vgg19_model_tuned.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5b891-5423-4049-97c6-7a48b8be203e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eadfe6a-a393-4bd9-a8d7-6a9137c5aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save training history to a JSON file\n",
    "# with open(save_dir + '/vgg19_history.json', 'w') as f:\n",
    "#     json.dump(history.history, f)\n",
    "\n",
    "# Load the model and history for evaluation without retraining\n",
    "model_vgg19_loaded = load_model(save_dir + '/vgg19_model_tuned.h5')\n",
    "\n",
    "# # Load the history\n",
    "# with open(save_dir + '/vgg19_history.json', 'r') as f:\n",
    "#     history_vgg19_loaded = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b911a357-2900-4848-b2e8-51a26a8ce41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "352f5f43-7d13-41fe-bf29-f68d3017ebc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 9s 73ms/step - loss: 0.4668 - accuracy: 0.8785\n",
      "Test accuracy vgg19: 87.85%\n",
      "198/198 [==============================] - 4s 22ms/step - loss: 0.4551 - accuracy: 0.8732\n",
      "Validation accuracy vgg19: 87.32%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model_vgg19_loaded.evaluate(test_generator)\n",
    "print(f'Test accuracy vgg19: {test_acc * 100:.2f}%')\n",
    "\n",
    "# Evaluate the model on the validation data\n",
    "validation_loss, validation_acc = model_vgg19_loaded.evaluate(validation_generator)\n",
    "print(f'Validation accuracy vgg19: {validation_acc * 100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4bd25a-c2aa-49ff-a008-315b4b1224bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68edd72f-cef4-4f7d-8c5e-0f6d7f2eebb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 3s 22ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       cow_1       1.00      0.00      0.00         2\n",
      "      cow_10       0.00      0.00      0.00         4\n",
      "     cow_101       1.00      0.00      0.00         2\n",
      "     cow_110       0.00      0.00      0.00         2\n",
      "     cow_112       0.00      0.00      0.00         4\n",
      "     cow_113       0.00      0.00      0.00         4\n",
      "     cow_118       0.00      0.00      0.00         2\n",
      "     cow_119       0.00      0.00      0.00         4\n",
      "     cow_120       0.00      0.00      0.00         4\n",
      "     cow_121       0.00      0.00      0.00         4\n",
      "     cow_122       0.00      0.00      0.00         4\n",
      "     cow_123       0.08      0.17      0.11         6\n",
      "     cow_124       0.25      0.25      0.25         4\n",
      "     cow_126       0.00      0.00      0.00         4\n",
      "     cow_127       0.00      0.00      0.00         6\n",
      "     cow_129       0.00      0.00      0.00         2\n",
      "      cow_13       0.00      0.00      0.00         4\n",
      "     cow_132       0.00      0.00      0.00         4\n",
      "     cow_134       0.00      0.00      0.00         4\n",
      "     cow_135       0.00      0.00      0.00         4\n",
      "     cow_136       0.00      0.00      0.00         4\n",
      "      cow_14       0.00      0.00      0.00         4\n",
      "     cow_140       0.00      0.00      0.00         2\n",
      "     cow_146       0.00      0.00      0.00         4\n",
      "     cow_157       0.00      0.00      0.00         2\n",
      "     cow_158       0.00      0.00      0.00         2\n",
      "      cow_16       0.00      0.00      0.00         4\n",
      "     cow_164       0.00      0.00      0.00         2\n",
      "     cow_166       0.00      0.00      0.00         2\n",
      "     cow_168       0.00      0.00      0.00         4\n",
      "      cow_17       0.00      0.00      0.00         4\n",
      "     cow_172       0.00      0.00      0.00         4\n",
      "     cow_173       0.00      0.00      0.00         4\n",
      "     cow_177       0.00      0.00      0.00         6\n",
      "     cow_179       0.00      0.00      0.00         2\n",
      "     cow_181       1.00      0.00      0.00         6\n",
      "     cow_186       0.00      0.00      0.00        10\n",
      "     cow_187       0.00      0.00      0.00         4\n",
      "     cow_190       0.00      0.00      0.00         6\n",
      "     cow_191       0.00      0.00      0.00         2\n",
      "     cow_194       0.00      0.00      0.00         2\n",
      "     cow_195       0.00      0.00      0.00         2\n",
      "     cow_196       0.00      0.00      0.00         2\n",
      "     cow_199       0.00      0.00      0.00         2\n",
      "       cow_2       0.00      0.00      0.00         2\n",
      "      cow_20       0.00      0.00      0.00         4\n",
      "     cow_201       0.00      0.00      0.00         8\n",
      "     cow_210       0.00      0.00      0.00         2\n",
      "     cow_212       0.00      0.00      0.00         4\n",
      "     cow_217       0.00      0.00      0.00         2\n",
      "     cow_223       0.00      0.00      0.00         2\n",
      "     cow_224       0.00      0.00      0.00         4\n",
      "     cow_229       0.00      0.00      0.00         2\n",
      "     cow_235       0.00      0.00      0.00         8\n",
      "      cow_24       0.00      0.00      0.00         2\n",
      "     cow_246       0.00      0.00      0.00         4\n",
      "     cow_247       1.00      0.00      0.00         2\n",
      "     cow_248       0.00      0.00      0.00         2\n",
      "     cow_249       0.00      0.00      0.00         2\n",
      "     cow_251       0.00      0.00      0.00         4\n",
      "     cow_252       1.00      0.00      0.00         2\n",
      "     cow_253       0.00      0.00      0.00         6\n",
      "     cow_254       0.00      0.00      0.00         6\n",
      "     cow_255       0.00      0.00      0.00         4\n",
      "     cow_256       0.00      0.00      0.00         4\n",
      "     cow_257       0.00      0.00      0.00         4\n",
      "     cow_258       0.00      0.00      0.00         8\n",
      "     cow_259       0.00      0.00      0.00         4\n",
      "     cow_260       0.00      0.00      0.00         6\n",
      "     cow_261       0.00      0.00      0.00         4\n",
      "     cow_262       0.00      0.00      0.00         6\n",
      "     cow_263       0.50      0.17      0.25         6\n",
      "     cow_264       1.00      0.00      0.00         4\n",
      "     cow_265       0.00      0.00      0.00         2\n",
      "     cow_266       1.00      1.00      1.00         0\n",
      "     cow_267       0.00      0.00      0.00         4\n",
      "     cow_268       0.00      0.00      0.00         6\n",
      "     cow_269       0.00      0.00      0.00         2\n",
      "      cow_27       0.00      0.00      0.00         4\n",
      "     cow_270       0.00      0.00      0.00         4\n",
      "     cow_271       1.00      0.00      0.00         2\n",
      "     cow_272       0.00      0.00      0.00         2\n",
      "     cow_273       0.00      0.00      0.00         4\n",
      "     cow_274       1.00      0.00      0.00         2\n",
      "     cow_275       0.00      0.00      0.00         2\n",
      "     cow_276       1.00      1.00      1.00         0\n",
      "     cow_277       0.00      0.00      0.00         4\n",
      "     cow_278       0.00      0.00      0.00         2\n",
      "     cow_279       0.00      0.00      0.00         6\n",
      "     cow_280       0.00      0.00      0.00         2\n",
      "     cow_281       0.00      0.00      0.00         2\n",
      "     cow_282       0.00      0.00      0.00         4\n",
      "     cow_283       0.00      0.00      0.00         4\n",
      "     cow_284       0.00      0.00      0.00         4\n",
      "     cow_285       0.00      0.00      0.00         8\n",
      "     cow_286       0.00      0.00      0.00         4\n",
      "     cow_287       0.00      0.00      0.00         2\n",
      "     cow_288       0.00      0.00      0.00         8\n",
      "     cow_289       0.00      0.00      0.00         4\n",
      "     cow_290       0.00      0.00      0.00         2\n",
      "     cow_291       0.00      0.00      0.00         6\n",
      "     cow_292       0.00      0.00      0.00         6\n",
      "     cow_293       1.00      0.00      0.00         2\n",
      "     cow_294       0.00      0.00      0.00         4\n",
      "     cow_295       0.00      0.00      0.00         4\n",
      "     cow_296       0.00      0.00      0.00         4\n",
      "     cow_297       0.00      0.00      0.00         2\n",
      "     cow_298       0.00      0.00      0.00         4\n",
      "     cow_299       0.00      0.00      0.00         2\n",
      "     cow_300       0.14      0.25      0.18         4\n",
      "     cow_301       0.11      0.12      0.12         8\n",
      "     cow_302       0.00      0.00      0.00         4\n",
      "     cow_303       0.00      1.00      0.00         0\n",
      "     cow_304       1.00      1.00      1.00         0\n",
      "     cow_308       0.00      0.00      0.00         2\n",
      "     cow_309       0.00      0.00      0.00         4\n",
      "     cow_310       0.00      0.00      0.00         2\n",
      "     cow_311       0.00      0.00      0.00         2\n",
      "     cow_312       0.00      0.00      0.00         2\n",
      "     cow_313       0.00      0.00      0.00         2\n",
      "     cow_314       0.00      0.00      0.00         2\n",
      "     cow_315       1.00      0.00      0.00         2\n",
      "     cow_319       0.00      0.00      0.00         2\n",
      "      cow_32       0.00      0.00      0.00         4\n",
      "     cow_320       0.00      0.00      0.00         4\n",
      "     cow_324       0.00      0.00      0.00         2\n",
      "     cow_327       0.00      0.00      0.00         2\n",
      "     cow_328       0.00      0.00      0.00         4\n",
      "     cow_329       0.00      0.00      0.00         4\n",
      "     cow_330       0.00      0.00      0.00         2\n",
      "     cow_331       0.00      0.00      0.00         4\n",
      "     cow_332       0.00      0.00      0.00         4\n",
      "     cow_333       0.00      0.00      0.00         2\n",
      "     cow_334       0.00      0.00      0.00         2\n",
      "     cow_336       0.00      0.00      0.00         4\n",
      "     cow_337       0.00      0.00      0.00         2\n",
      "     cow_339       0.00      0.00      0.00         2\n",
      "      cow_34       0.00      0.00      0.00         6\n",
      "     cow_341       0.00      0.00      0.00         2\n",
      "     cow_342       0.00      0.00      0.00         4\n",
      "     cow_343       0.00      0.00      0.00         2\n",
      "     cow_346       1.00      1.00      1.00         0\n",
      "     cow_347       0.00      0.00      0.00         2\n",
      "     cow_349       0.00      0.00      0.00         2\n",
      "      cow_35       0.00      0.00      0.00         4\n",
      "     cow_352       0.00      0.00      0.00         2\n",
      "      cow_39       0.00      0.00      0.00         4\n",
      "      cow_40       0.00      0.00      0.00         2\n",
      "      cow_41       0.00      0.00      0.00         2\n",
      "      cow_44       0.00      0.00      0.00         6\n",
      "      cow_49       0.25      0.25      0.25         4\n",
      "       cow_5       0.00      0.00      0.00         2\n",
      "      cow_50       0.00      0.00      0.00         2\n",
      "      cow_54       0.00      0.00      0.00         2\n",
      "      cow_55       0.00      0.00      0.00         2\n",
      "      cow_57       0.00      0.00      0.00         2\n",
      "      cow_58       0.00      0.00      0.00         4\n",
      "      cow_64       0.00      0.00      0.00         2\n",
      "      cow_68       0.00      0.00      0.00         8\n",
      "      cow_69       0.00      0.00      0.00         4\n",
      "      cow_74       0.00      0.00      0.00         4\n",
      "      cow_79       1.00      0.00      0.00         2\n",
      "       cow_8       0.00      0.00      0.00         2\n",
      "      cow_80       0.00      0.00      0.00         4\n",
      "      cow_83       1.00      1.00      1.00         0\n",
      "      cow_84       0.00      0.00      0.00         2\n",
      "      cow_85       0.00      0.00      0.00         2\n",
      "      cow_88       1.00      1.00      1.00         0\n",
      "      cow_90       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.01      0.01      0.01       568\n",
      "   macro avg       0.11      0.05      0.04       568\n",
      "weighted avg       0.06      0.01      0.01       568\n",
      "\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "predictions = model_vgg19_loaded.predict(test_generator)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels from the test set generator\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Get class labels (optional, but useful for the classification report)\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Ensure the classification report and confusion matrix consider all classes\n",
    "labels = list(test_generator.class_indices.values())\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, predicted_labels, labels=labels, target_names=class_labels, zero_division=1))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(confusion_matrix(true_labels, predicted_labels, labels=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53262241-663c-4cf6-9692-bbe5ac9b1bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e8ea323-abe5-42f5-b92f-bba0ef6a28e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Predicted class: cow_310\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to load and preprocess the image\n",
    "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array /= 255.0  # Rescale pixel values to [0, 1]\n",
    "    return img_array\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = os.path.join(save_dir, 'vgg19_model_tuned.h5')\n",
    "model_InceptionV3_loaded = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Path to the image to predict\n",
    "img_path = r\"F:\\Thesis\\1.bigDataSet\\Final Dataset\\cow_20\\cow_20_1.jpg\"\n",
    "\n",
    "# Preprocess the image\n",
    "preprocessed_img = load_and_preprocess_image(img_path)\n",
    "\n",
    "# Make the prediction\n",
    "prediction = model_vgg19_loaded.predict(preprocessed_img)\n",
    "\n",
    "# Get the class indices from the training generator\n",
    "class_indices = train_generator.class_indices\n",
    "# Reverse the class indices to get a mapping from indices to class names\n",
    "indices_to_class = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Get the predicted class index\n",
    "predicted_class_index = np.argmax(prediction[0])\n",
    "# Get the predicted class name\n",
    "predicted_class_name = indices_to_class[predicted_class_index]\n",
    "\n",
    "# Print the predicted class name\n",
    "print(f\"Predicted class: {predicted_class_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a23536a-5199-4ff8-9a4f-f6f99f6f04b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b479cfe-3db4-4719-b3b9-a31fc2522d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
